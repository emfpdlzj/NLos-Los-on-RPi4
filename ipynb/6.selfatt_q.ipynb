{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Self-Attention-Assisted Classifier (UWB)\n",
    "# - Argmax Feature Selection (±50 → len 100)\n",
    "# - 2-stage training (FE freeze)\n",
    "# - PTQ: int8 weights + float32 activations\n",
    "# - TFLite inference & accuracy comparison\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers as L, Model, Input\n",
    "import uwb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 0) 데이터 로드 & 프리앰블 정규화\n",
    "# -----------------------------\n",
    "data = uwb_dataset.import_from_files()\n",
    "csv_logger = CSVLogger('result/log_sa_ptq.csv', append=False)\n",
    "\n",
    "for item in data:\n",
    "    # item[2] = preamble symbols count\n",
    "    item[15:] = item[15:] / float(item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Split\n",
    "# -----------------------------\n",
    "train = data[:30000, :]\n",
    "np.random.shuffle(train)\n",
    "\n",
    "x_train = train[:30000, 15:]\n",
    "y_train = train[:30000, 0].astype(int)\n",
    "\n",
    "x_test  = data[30000:, 15:]\n",
    "y_test  = data[30000:, 0].astype(int)\n",
    "\n",
    "# validation\n",
    "x_val = x_train[25000:]\n",
    "y_val = y_train[25000:]\n",
    "x_train = x_train[:25000]\n",
    "y_train = y_train[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# 2) Argmax Feature Selection & Padding\n",
    "# ---------------------------------------\n",
    "def argmax_window(X, w=50):\n",
    "    out = []\n",
    "    for row in X:\n",
    "        m = int(row.argmax())\n",
    "        s = max(0, m - w)\n",
    "        e = m + w\n",
    "        out.append(row[s:e])\n",
    "    return np.asarray(out)\n",
    "\n",
    "def pad_to_100(X):\n",
    "    if X.shape[1] == 100:\n",
    "        return X\n",
    "    Z = np.zeros((X.shape[0], 100), dtype=X.dtype)\n",
    "    L = min(100, X.shape[1])\n",
    "    Z[:, :L] = X[:, :L]\n",
    "    return Z\n",
    "\n",
    "x_train = pad_to_100(argmax_window(x_train, 50))\n",
    "x_val   = pad_to_100(argmax_window(x_val,   50))\n",
    "x_test  = pad_to_100(argmax_window(x_test,  50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 3) 모델 정의 (Functional API)\n",
    "#     Feature Extractor → Self-Attention → Classifier\n",
    "# -----------------------------\n",
    "L_IN  = 100    # input length\n",
    "D_FE  = 16     # feature dim after extractor\n",
    "SCALE = 1.0 / np.sqrt(D_FE)\n",
    "\n",
    "inp = Input(shape=(L_IN,), name='input_1')                 # (None,100)\n",
    "x   = L.Lambda(lambda z: tf.expand_dims(z, -1), name='expand')(inp)  # (None,100,1)\n",
    "\n",
    "# --- Feature Extraction (Dense(30)→BN→Dense(16,ReLU)) ---\n",
    "fe = L.Conv1D(30, 1, use_bias=True, name='fe_dense30')(x)           # (None,100,30)\n",
    "fe = L.BatchNormalization(name='fe_bn30')(fe)\n",
    "fe = L.Conv1D(D_FE, 1, activation='relu', name='fe_dense16')(fe)    # (None,100,16)\n",
    "fe_out = fe\n",
    "\n",
    "# --- Self-Attention (Q/K/V: 16→16) ---\n",
    "q = L.Conv1D(D_FE, 1, use_bias=True, name='sa_q')(fe_out)\n",
    "q = L.BatchNormalization(name='sa_q_bn')(q)\n",
    "k = L.Conv1D(D_FE, 1, use_bias=True, name='sa_k')(fe_out)\n",
    "k = L.BatchNormalization(name='sa_k_bn')(k)\n",
    "v = L.Conv1D(D_FE, 1, use_bias=True, name='sa_v')(fe_out)\n",
    "v = L.BatchNormalization(name='sa_v_bn')(v)\n",
    "\n",
    "scores  = L.Lambda(lambda t: tf.matmul(t[0], t[1], transpose_b=True) * SCALE,\n",
    "                   name='attn_scores')([q, k])                      # (None,100,100)\n",
    "weights = L.Softmax(axis=-1, name='attn_softmax')(scores)           # (None,100,100)\n",
    "context = L.Lambda(lambda t: tf.matmul(t[0], t[1]),\n",
    "                   name='attn_ctx')([weights, v])                   # (None,100,16)\n",
    "\n",
    "# --- Classifier (Flatten→Dense(42)→Dropout→Dense(16)→Dropout→Dense(2,Softmax)) ---\n",
    "flat = L.Flatten(name='flatten')(context)                            # (None,1600)\n",
    "c    = L.Dense(42, activation='relu', name='cls_dense42')(flat)\n",
    "c    = L.Dropout(0.5, name='drop1')(c)\n",
    "c    = L.Dense(16, activation='relu', name='cls_dense16')(c)\n",
    "c    = L.Dropout(0.5, name='drop2')(c)\n",
    "out  = L.Dense(2, activation='softmax', name='output')(c)\n",
    "\n",
    "model = Model(inp, out, name='SA_Assisted_Classifier')\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 4) 학습 (1단계: end-to-end)\n",
    "# -----------------------------\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[csv_logger],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) 학습 (2단계: Feature Extractor Frozen)\n",
    "# -----------------------------\n",
    "for name in ['fe_dense30', 'fe_bn30', 'fe_dense16']:\n",
    "    model.get_layer(name).trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(5e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=4,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"6.selfatt_q.h5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6) Keras 기준 정확도\n",
    "# -----------------------------\n",
    "keras_prob = model.predict(x_test, batch_size=256, verbose=0)\n",
    "keras_pred = np.argmax(keras_prob, axis=1)\n",
    "print(\"[Keras] acc :\", accuracy_score(y_test, keras_pred))\n",
    "print(classification_report(y_test, keras_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) PTQ (weights int8 + activations float32)\n",
    "#     calibration set: 500 샘플\n",
    "# -----------------------------\n",
    "calib = x_val[:500].astype(np.float32)\n",
    "\n",
    "def representative_dataset():\n",
    "    for i in range(calib.shape[0]):\n",
    "        yield [calib[i:i+1]]\n",
    "\n",
    "# FP32 TFLite (baseline)\n",
    "conv_fp32 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_fp32 = conv_fp32.convert()\n",
    "open(\"sa_cls_fp32.tflite\", \"wb\").write(tflite_fp32)\n",
    "\n",
    "# PTQ: int8 weights + float32 activations (dynamic-range)\n",
    "conv_int8w = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "conv_int8w.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "conv_int8w.representative_dataset = representative_dataset\n",
    "conv_int8w.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS\n",
    "]\n",
    "tflite_int8w = conv_int8w.convert()\n",
    "open(\"sa_cls_int8w_floatact.tflite\", \"wb\").write(tflite_int8w)\n",
    "\n",
    "print(\"FP32 size (KB):\", len(tflite_fp32)/1024)\n",
    "print(\"INT8W size (KB):\", len(tflite_int8w)/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8) TFLite 추론 유틸\n",
    "# -----------------------------\n",
    "def tflite_predict(tflite_model_bytes, X):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model_bytes)\n",
    "    interpreter.allocate_tensors()\n",
    "    in_det  = interpreter.get_input_details()[0]\n",
    "    out_det = interpreter.get_output_details()[0]\n",
    "    input_idx  = in_det['index']\n",
    "    output_idx = out_det['index']\n",
    "\n",
    "    # dynamic-range PTQ는 보통 float32 입출력\n",
    "    if in_det['dtype'] == np.int8:\n",
    "        # (full-int8 대비 안전용 처리)\n",
    "        scale, zp = in_det['quantization']\n",
    "        Xq = np.clip(np.round(X/scale + zp), -128, 127).astype(np.int8)\n",
    "        feed = Xq\n",
    "    else:\n",
    "        feed = X.astype(np.float32)\n",
    "\n",
    "    preds = []\n",
    "    for i in range(X.shape[0]):\n",
    "        interpreter.set_tensor(input_idx, feed[i:i+1])\n",
    "        interpreter.invoke()\n",
    "        out = interpreter.get_tensor(output_idx)\n",
    "        if out_det['dtype'] == np.int8:\n",
    "            os, oz = out_det['quantization']\n",
    "            out = (out.astype(np.float32) - oz) * os\n",
    "        preds.append(out[0])\n",
    "    return np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 9) 정확도 비교 (Keras vs TFLite FP32 vs TFLite PTQ)\n",
    "# -----------------------------\n",
    "tfl_fp32_prob = tflite_predict(tflite_fp32, x_test)\n",
    "tfl_fp32_pred = np.argmax(tfl_fp32_prob, axis=1)\n",
    "print(\"[TFLite FP32] acc :\", accuracy_score(y_test, tfl_fp32_pred))\n",
    "\n",
    "tfl_int8w_prob = tflite_predict(tflite_int8w, x_test)\n",
    "tfl_int8w_pred = np.argmax(tfl_int8w_prob, axis=1)\n",
    "print(\"[TFLite INT8-weights (float act)] acc :\", accuracy_score(y_test, tfl_int8w_pred))\n",
    "print(classification_report(y_test, tfl_int8w_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 10) Confusion Matrix (PTQ 모델)\n",
    "# -----------------------------\n",
    "cm = confusion_matrix(y_test, tfl_int8w_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix (SA-PTQ)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# (옵션) Full-INT8 템플릿\n",
    "# -----------------------------\n",
    "# conv_fullint8 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# conv_fullint8.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# conv_fullint8.representative_dataset = representative_dataset\n",
    "# conv_fullint8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# conv_fullint8.inference_input_type  = tf.int8\n",
    "# conv_fullint8.inference_output_type = tf.int8\n",
    "# tflite_fullint8 = conv_fullint8.convert()\n",
    "# open(\"sa_cls_full_int8.tflite\", \"wb\").write(tflite_fullint8)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
