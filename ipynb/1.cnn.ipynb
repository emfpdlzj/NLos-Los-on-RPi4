{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'uwb_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muwb_dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'uwb_dataset'"
     ]
    }
   ],
   "source": [
    "import uwb_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Input shape       : (100, 1)                                                         |\n",
    "Conv1D layers     : 3 layers (filters: 16 → 32 → 64, kernel: 3)                      |\n",
    "Pooling           : MaxPooling1D (pool=2, stride=2)                                  |\n",
    "Final layers      : GlobalMaxPooling → Dense(128) + Dropout(0.5) → Dense(1, sigmoid) |\n",
    "Optimizer         : Adam                                                             |\n",
    "Loss              : Binary Crossentropy                                              |\n",
    "Batch size        : 64                                                               |\n",
    "Epochs            : 10                                                               |\n",
    "Feature selection : CIR에서 신호 피크 기준 좌우 50개 (총 100개)                                   |\n",
    "Dataset split     : Train: 25,000 / Val: 5,000 / Test: 12,000                        |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw data\n",
    "data = uwb_dataset.import_from_files()\n",
    "csv_logger = CSVLogger('result/log.csv', append=False)\n",
    "\n",
    "# Preamble(프리앰블): 통신에서 신호의 시작을 알리고, 수신 동기를 맞추기 위해 보내는 특별한 비트 패턴\n",
    "# divide CIR by RX preable count (get CIR of single preamble pulse)\n",
    "# item[2] represents number of acquired preamble symbols\n",
    "for item in data:\n",
    "    item[15:] = item[15:]/float(item[2])\n",
    "\n",
    "# test data\n",
    "train = data[:30000, :] #앞 에서부터 30000개와 모든열을 가져와 잘라냄  (2차원)\n",
    "np.random.shuffle(train) #랜덤으로 섞음.\n",
    "x_train = train[:30000, 15:] #train의 앞에서부터 30000개 row, 각 row의 15번부터 끝까지 슬라이싱. \n",
    "y_train = train[:30000, 0] #앞 에서부터 30000개와 0개의 열을 가져와 잘라냄 (1차원)\n",
    "x_test = data[30000:, 15:]\n",
    "y_test = data[30000:, 0]\n",
    "\n",
    "# feed data 검증데이터 \n",
    "x_val = x_train[25000:] #x_val은 x_train의 250000번째부터 끝까지\n",
    "y_val = y_train[25000:]\n",
    "x_train = x_train[:25000] #x_train의 앞에서 24999까지만 남김. \n",
    "y_train = y_train[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nnew=[]\n",
    "for item in x_train:\n",
    "    item = item[max([0,item.argmax()-50]) : item.argmax()+50] \n",
    "    #신호가 강한 구간 기준 앞 뒤로 50개씩 총100개 구간으로 자른다. \n",
    "    Nnew.append(item)\n",
    "x_train = np.asarray(Nnew) \n",
    "# np.assary(): 리스트를 numpy배열로 변환하는 함수\n",
    "\n",
    "Nnew=[]\n",
    "for item in x_test:\n",
    "    item = item[max([0,item.argmax()-50]) : item.argmax()+50]\n",
    "    Nnew.append(item)\n",
    "x_test = np.asarray(Nnew)\n",
    "\n",
    "Nnew=[]\n",
    "for item in x_val:\n",
    "    item = item[max([0,item.argmax()-50]) : item.argmax()+50]\n",
    "    Nnew.append(item)\n",
    "x_val = np.asarray(Nnew)\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total 1016 data for CIR\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "# 입력 shape: (샘플 수, 100, 1) → reshape 필요\n",
    "# 1개의 hidden layer를 가진 3개의 MLP 구조\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(100, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # LoS/NLoS → binary classification\n",
    "\n",
    "print(model.summary())\n",
    "#CNN기반의 분류 모델 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "hist = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_val, y_val),callbacks=[csv_logger])\n",
    "# epochs: 전체 훈련 데이터셋이 훈련 중 네트워크를 통해 몇 번이나 실행될 것인지 지정.\n",
    "# validation_data : 검증 데이터셋을 지정하는 인수\n",
    "# SGD: 가장 기본적인 최적화 알고리즘, 미분 가능함 함수에서 기울기를 계산하여 가중치를 업데이트한다. \n",
    "model.save(\"1.cnn.h5\");\n",
    "# evaluation\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=64)\n",
    "# batch_size: 정확도를 측정하고 가중치와 편향을 업데이트 하기 전에 네트워크에 공급할 훈련 데이터의 수를 지정\n",
    "# 16또는 32로 시작해서 효과적인값을 실험해보는게 좋음.\n",
    "print('## evaluation loss and metrics ##')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# macro avg: 클래스마다 F1, Precision, Recall을 구한 뒤, 단순 평균\n",
    "# weighted avg: 각 클래스의 F1, Precision, Recall에 해당 클래스의 샘플 수로 가중치를 줘서 평균 낸 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 시각화 - confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"1_cnn.h5\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
