{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 0) Imports ====\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import uwb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 1) 데이터 로드 & 프리앰블 정규화 ====\n",
    "data = uwb_dataset.import_from_files()\n",
    "csv_logger = CSVLogger('result/log.csv', append=False)\n",
    "\n",
    "for item in data:\n",
    "    item[15:] = item[15:] / float(item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2) Split ====\n",
    "train = data[:30000, :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:30000, 15:]\n",
    "y_train = train[:30000, 0].astype(int)\n",
    "\n",
    "x_test  = data[30000:, 15:]\n",
    "y_test  = data[30000:, 0].astype(int)\n",
    "\n",
    "# 검증셋\n",
    "x_val = x_train[25000:]\n",
    "y_val = y_train[25000:]\n",
    "x_train = x_train[:25000]\n",
    "y_train = y_train[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'keras_env (Python 3.11.13)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emfpdlzj/Desktop/aaa/keras_env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ==== 3) Feature selection: argmax 윈도우(±50 → 길이 최대 100) ====\n",
    "def argmax_window(X, w=50):\n",
    "    out = []\n",
    "    for row in X:\n",
    "        m = int(row.argmax())\n",
    "        s = max(0, m - w)\n",
    "        e = m + w\n",
    "        out.append(row[s:e])\n",
    "    return np.asarray(out)\n",
    "\n",
    "def pad_to_100(X):\n",
    "    if X.shape[1] == 100:\n",
    "        return X\n",
    "    Z = np.zeros((X.shape[0], 100), dtype=X.dtype)\n",
    "    L = min(100, X.shape[1])\n",
    "    Z[:, :L] = X[:, :L]\n",
    "    return Z\n",
    "\n",
    "x_train = pad_to_100(argmax_window(x_train, 50))\n",
    "x_val   = pad_to_100(argmax_window(x_val,   50))\n",
    "x_test  = pad_to_100(argmax_window(x_test,  50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4) 사진과 유사한 MLP ====\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(100,), use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 5) 학습 ====\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10, batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[csv_logger],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 6) (기준) Keras 정확도 ====\n",
    "keras_prob = model.predict(x_test, batch_size=256, verbose=0)\n",
    "keras_pred = np.argmax(keras_prob, axis=1)\n",
    "print(\"Keras accuracy :\", accuracy_score(y_test, keras_pred))\n",
    "print(classification_report(y_test, keras_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 7) PTQ: 가중치 int8, activation float32 (논문 설명과 동일) ====\n",
    "#    - 모델 저장/로딩 없이 from_keras_model(model) 사용\n",
    "#    - calibration set: 검증셋에서 500개 사용\n",
    "calib = x_val[:500].astype(np.float32)\n",
    "\n",
    "def representative_dataset():\n",
    "    for i in range(calib.shape[0]):\n",
    "        yield [calib[i:i+1]]\n",
    "\n",
    "# (참고) float32 TFLite (baseline)\n",
    "conv_fp32 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_fp32 = conv_fp32.convert()\n",
    "open(\"mlp_fp32.tflite\", \"wb\").write(tflite_fp32)\n",
    "\n",
    "# PTQ (weights int8, activations float32 → dynamic-range quantization)\n",
    "conv_int8w = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "conv_int8w.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "conv_int8w.representative_dataset = representative_dataset\n",
    "# 지원 op을 넉넉히 허용(빌트인 float + int8 혼용)\n",
    "conv_int8w.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS\n",
    "]\n",
    "tflite_int8w = conv_int8w.convert()\n",
    "open(\"mlp_int8w_floatact.tflite\", \"wb\").write(tflite_int8w)\n",
    "\n",
    "print(\"FP32 size (KB):\", len(tflite_fp32)/1024)\n",
    "print(\"INT8W size (KB):\", len(tflite_int8w)/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 8) TFLite 추론 유틸 ====\n",
    "def tflite_predict(tflite_model_bytes, X):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model_bytes)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_idx  = interpreter.get_input_details()[0]['index']\n",
    "    output_idx = interpreter.get_output_details()[0]['index']\n",
    "    # dynamic-range 모델은 입력/출력이 float32인 경우가 일반적\n",
    "    X = X.astype(np.float32)\n",
    "    preds = []\n",
    "    for i in range(X.shape[0]):\n",
    "        interpreter.set_tensor(input_idx, X[i:i+1])\n",
    "        interpreter.invoke()\n",
    "        out = interpreter.get_tensor(output_idx)  # shape (1,2)\n",
    "        preds.append(out[0])\n",
    "    return np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 9) FP32/INT8W-FLOATACT 정확도 비교 ====\n",
    "tfl_fp32_prob = tflite_predict(tflite_fp32, x_test)\n",
    "tfl_fp32_pred = np.argmax(tfl_fp32_prob, axis=1)\n",
    "\n",
    "print(\"TFLite FP32 accuracy :\", accuracy_score(y_test, tfl_fp32_pred))\n",
    "\n",
    "tfl_int8w_prob = tflite_predict(tflite_int8w, x_test)\n",
    "tfl_int8w_pred = np.argmax(tfl_int8w_prob, axis=1)\n",
    "print(\"TFLite INT8-weights (float act) accuracy :\", accuracy_score(y_test, tfl_int8w_pred))\n",
    "print(classification_report(y_test, tfl_int8w_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, tfl_int8w_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix (TFLite INT8W)')\n",
    "plt.show()\n",
    "\n",
    "model.save(\"5.mlp_q.h5\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
