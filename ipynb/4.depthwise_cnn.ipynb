{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uwb_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, SeparableConv1D, BatchNormalization, Activation,\n",
    "                          MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout,\n",
    "                          Add, Conv1D)\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1) 데이터 로드 & 전처리 (동일)\n",
    "# ------------------------\n",
    "data = uwb_dataset.import_from_files()\n",
    "csv_logger = CSVLogger('result/log.csv', append=False)\n",
    "\n",
    "for item in data:\n",
    "    item[15:] = item[15:]/float(item[2])\n",
    "\n",
    "train = data[:30000, :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:30000, 15:]\n",
    "y_train = train[:30000, 0]\n",
    "x_test  = data[30000:, 15:]\n",
    "y_test  = data[30000:, 0]\n",
    "\n",
    "x_val = x_train[25000:]; y_val = y_train[25000:]\n",
    "x_train = x_train[:25000]; y_train = y_train[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_window(arr):\n",
    "    out=[]\n",
    "    for row in arr:\n",
    "        a = int(row.argmax())\n",
    "        out.append(row[max(0,a-50):a+50])\n",
    "    return np.asarray(out)\n",
    "\n",
    "x_train = slice_window(x_train)[..., np.newaxis]  # (N,100,1)\n",
    "x_val   = slice_window(x_val)[...,   np.newaxis]\n",
    "x_test  = slice_window(x_test)[...,  np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# 2) Xception-1D (사진 구조 동일)\n",
    "#    Entry → Middle(8회 반복) → Exit → GAP → FC → Sigmoid\n",
    "# ------------------------\n",
    "def relu_sepconv_bn(x, filters, k=3, name=None):\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv1D(filters, k, padding='same', use_bias=False, name=name)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = Input(shape=(100,1))\n",
    "\n",
    "# Entry flow\n",
    "x = Conv1D(32, 3, strides=2, padding='same', use_bias=False)(inp)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv1D(64, 3, padding='same', use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Block 1: 128, downsample + residual proj\n",
    "res = Conv1D(128, 1, strides=2, padding='same', use_bias=False)(x)\n",
    "res = BatchNormalization()(res)\n",
    "x = relu_sepconv_bn(x, 128, 3)\n",
    "x = MaxPooling1D(3, strides=2, padding='same')(x)\n",
    "x = Add()([x, res])\n",
    "\n",
    "# Block 2: 256\n",
    "res = Conv1D(256, 1, strides=2, padding='same', use_bias=False)(x)\n",
    "res = BatchNormalization()(res)\n",
    "x = relu_sepconv_bn(x, 256, 3)\n",
    "x = MaxPooling1D(3, strides=2, padding='same')(x)\n",
    "x = Add()([x, res])\n",
    "\n",
    "# Block 3: 728\n",
    "res = Conv1D(728, 1, strides=2, padding='same', use_bias=False)(x)\n",
    "res = BatchNormalization()(res)\n",
    "x = relu_sepconv_bn(x, 728, 3)\n",
    "x = MaxPooling1D(3, strides=2, padding='same')(x)\n",
    "x = Add()([x, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle flow: 8 times (no downsample, residual identity)\n",
    "for i in range(8):\n",
    "    res = x\n",
    "    x = relu_sepconv_bn(x, 728, 3, name=f\"mid_sep_{i}_a\")\n",
    "    x = relu_sepconv_bn(x, 728, 3, name=f\"mid_sep_{i}_b\")\n",
    "    x = relu_sepconv_bn(x, 728, 3, name=f\"mid_sep_{i}_c\")\n",
    "    x = Add()([x, res])\n",
    "\n",
    "# Exit flow\n",
    "res = Conv1D(1024, 1, strides=2, padding='same', use_bias=False)(x)\n",
    "res = BatchNormalization()(res)\n",
    "\n",
    "x = relu_sepconv_bn(x, 728, 3)\n",
    "x = relu_sepconv_bn(x, 1024, 3)\n",
    "x = MaxPooling1D(3, strides=2, padding='same')(x)\n",
    "x = Add()([x, res])\n",
    "\n",
    "x = relu_sepconv_bn(x, 1536, 3)\n",
    "x = relu_sepconv_bn(x, 2048, 3)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(1, activation='sigmoid')(x)  # 이진 분류\n",
    "\n",
    "model = Model(inp, out)\n",
    "model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# 3) 학습 / 평가 / 리포트\n",
    "# ------------------------\n",
    "history = model.fit(\n",
    "    x_train, y_train, epochs=10, batch_size=64,\n",
    "    validation_data=(x_val, y_val), callbacks=[csv_logger], verbose=1\n",
    ")\n",
    "\n",
    "print('## evaluation ##')\n",
    "print(model.evaluate(x_test, y_test, batch_size=64))\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "model.save(\"4.depthwise_cnn.h5\");"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
