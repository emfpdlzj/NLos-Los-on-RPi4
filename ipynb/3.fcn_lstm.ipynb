{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uwb_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, Conv1D, BatchNormalization, Activation,\n",
    "                        GlobalAveragePooling1D, Dense, Dropout,\n",
    "                          LSTM, Permute, Concatenate)\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  데이터 로드 & 전처리 \n",
    "data = uwb_dataset.import_from_files()\n",
    "csv_logger = CSVLogger('result/log.csv', append=False)\n",
    "\n",
    "for item in data:\n",
    "    item[15:] = item[15:] / float(item[2])\n",
    "\n",
    "train = data[:30000, :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:30000, 15:]\n",
    "y_train = train[:30000, 0]\n",
    "x_test  = data[30000:, 15:]\n",
    "y_test  = data[30000:, 0]\n",
    "\n",
    "x_val = x_train[25000:]\n",
    "y_val = y_train[25000:]\n",
    "x_train = x_train[:25000]\n",
    "y_train = y_train[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_window(arr):\n",
    "    Nnew=[]\n",
    "    for item in arr:\n",
    "        idx = int(item.argmax())\n",
    "        start = max(0, idx - 50)\n",
    "        end   = idx + 50\n",
    "        Nnew.append(item[start:end])\n",
    "    return np.asarray(Nnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = slice_window(x_train)\n",
    "x_val   = slice_window(x_val)\n",
    "x_test  = slice_window(x_test)\n",
    "\n",
    "# Conv1D/LSTM 입력 차원: (samples, timesteps, channels)\n",
    "x_train = x_train[..., np.newaxis]  # -> (N, 100, 1)\n",
    "x_val   = x_val[..., np.newaxis]\n",
    "x_test  = x_test[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FCN-LSTM 모델 (Functional API)\n",
    "\n",
    "inp = Input(shape=(100, 1))\n",
    "\n",
    "# FCN \n",
    "x = Conv1D(128, 8, padding='valid', strides=1)(inp)\n",
    "x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "\n",
    "x = Conv1D(256, 5, padding='valid', strides=1)(x)\n",
    "x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "\n",
    "x = Conv1D(128, 3, padding='valid', strides=1)(x)\n",
    "x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "\n",
    "gap = GlobalAveragePooling1D(name=\"fcn_gap\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM \n",
    "# Dimension shuffle: (timesteps, channels) -> (channels, timesteps)\n",
    "p = Permute((2, 1), name=\"dim_shuffle\")(inp)  # (1, 100)\n",
    "\n",
    "# units는 데이터 크기에 맞춰 조절해야함. (작으면 underfit, 크면 overfit)\n",
    "lstm_out = LSTM(64, name=\"lstm_block\")(p)\n",
    "\n",
    "# Concatenate & Classifier \n",
    "h = Concatenate(name=\"concat_gap_lstm\")([gap, lstm_out])\n",
    "h = Dense(128, activation='relu')(h)\n",
    "h = Dropout(0.5)(h)\n",
    "out = Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[csv_logger],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 & 리포트\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print('## evaluation loss and metrics ##')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "model.save(\"3.fcn_lstm.h5\");"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
