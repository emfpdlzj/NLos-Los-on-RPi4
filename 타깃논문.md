# 타깃논문 공부
- **Reference**: A review on TinyML:
State-of-the-art and prospects
Partha Pratim Ray (2021)
Department of Computer Applications,
Sikkim University, India

### 세미나 때 발표한 타깃논문 정리본
---

## 📘 1. Introduction  
- **문제점:**  
  - ML 모델은 막대한 전력과 메모리를 요구함  
  - 하드웨어와 웹 기술 간의 격차 존재 → 이종(heterogeneous) 환경  

- **TinyML 개념:**  
  - 초저전력 IoT 기기에서 머신러닝 수행  
  - “Cloud to Embedded” 패러다임  
  - 에너지 효율, 오프라인 작동, 프라이버시 보장  
  - TinyML의 현황과 잠재력 검토  

---

## ⚙️ 2. Background of TinyML

### 🔹 Basics of TinyML
- 자원 제약 조건에서도 높은 정확도를 유지하도록 최적화  
- 요구사항:
  1. 저전력(배터리 기반)
  2. 수십억 개의 IoT 센서 확장성
  3. 수 KB 코드로 실행 가능해야 함  

### 🔹 Constraints
| 항목 | 요구수준 |
|------|-----------|
| 에너지 | 10–100 mAh 배터리 |
| 프로세서 | 10–1000 MHz |
| 메모리 | 1 MB 이하 |
| 비용 | 누적 시 높음 |

### 🔹 Definition
- mW 이하 전력 범위에서 작동  
- 온디바이스 분석 수행  
- IoT/WSN(무선 센서 네트워크)에 적합  

### 🔹 TinyML in Edge
1. 센서가 원시 데이터를 수집  
2. 필터링 및 FIFO 저장  
3. IoT 기반 연결을 통해 장기 메모리로 전송  

---

## 🧩 3. TinyML Tool Sets  

### 🔸 Hardware
- **프로세서:** ARM Cortex-M4 (< 100 MHz)  
- **연결성:** BLE, Wi-Fi  
- **전원:** Li-Po, 코인 배터리  

### 🔸 Software & Libraries

| Tool | Target | 특징 |
|------|--------|------|
| **TensorFlow Lite / TFLM** | Android, iOS, MCU | 300KB 바이너리, 양자화 지원 |
| **uTensor** | Mbed, STM32 | 2KB 크기, Keras→C++ 변환 |
| **Edge Impulse** | Cloud / Edge | WebAssembly, 멀티보드 지원 |
| **NanoEdge AI Studio** | STM32, Arduino | 이상 탐지, flash 최적화 |
| **PyTorch Mobile** | Android, iOS | TorchScript, XNNPACK |
| **ELL (Embedded Learning Library)** | Raspberry Pi, micro:bit | 오프라인 분류, 간단 배포 |
| **STM32Cube.AI** | STM32 | ONNX/PyTorch 호환, 메모리 최적화 |
| **MicroTVM** | MCU | 텐서 연산 최적화, OpenOCD 인터페이스 |

---

## ⚡ 4. Key Enablers of TinyML

### 🔹 TinyML-as-a-Service
- 클라우드 없이 로컬 추론  
- **Model Compiler 기술:**  
  - Quantization (양자화)  
  - Pruning (매개변수 제거)  
  - Fusion (연산 결합)

### 🔹 Hyperdimensional Computing (HDC)
- 고차원 벡터(>1000차원)로 데이터 표현  
- Hamming/Cosine 유사도 기반 분류  

### 🔹 Swapping
- 모델 일부를 외부 플래시 메모리와 교환하며 실행  

### 🔹 Attention Condenser
- Self-Attention 기반 핵심 특징 압축  
- 중요 특징만 선택적으로 학습  

### 🔹 Constrained NAS (Neural Architecture Search)
- 하드웨어 제약 고려 자동 모델 탐색  

### 🔹 Model Compression
- **TAC (Tiny Anomaly Compressor)**: 수학적 모델 없이 데이터 압축  

### 🔹 Quantization
- **QAT (Quantization Aware Training)**  
  - 저비트 정밀도 모델 학습  
  - 병목구간 최소화  
- **HAQ (Hardware-Aware Quantization)**  
  - 강화학습 기반 자동 비트폭 선택  

### 🔹 Once-for-All Network (OFA)
- Progressive Shrinking Algorithm (PSA)  
- 다양한 서브넷 구성 → 동일 정확도 유지  
- HW별 최적 서브넷 자동 생성  

### 🔹 TinyML Benchmark
- **MLPerf Tiny**: 표준화된 벤치마크  
  - PTQ, 다양한 하드웨어 비교  
  - 10개 데이터셋, 14개 보드 지원  

### 🔹 On-Device Computing & Accelerator
- **SEEDoT:** 고정소수점 코드 최적화  
- **HBDCA:** 8-bit 양자화 가속  
- **SWIS:** Sparsity-aware systolic array  
- **GrAI:** 이벤트 기반 스파스 컴퓨팅  
- **K-NN + Incremental Learning:** 실시간 적응형 모델  

### 🔹 In-Processor Learning
- **DQN, RascaNet:** RNN을 활용한 효율적 메모리 학습  

---

## 🧱 5. TinyML Frameworks  

### 📦 산업계 프레임워크
- **주요 개발 주체:** Fraunhofer IMS, Cartesiam  
- **공통 특징:**  
  - ARM Cortex 계열 지원  
  - C/C++ 출력  
  - 외부 라이브러리: TensorFlow, Keras, PyTorch, ONNX 등  

### 🧪 연구 그룹 프레임워크
- **PULP:** 비신경망 ML 커널, 초저전력  
- **FANN-on-MCU:** 오픈소스, 에너지 최소화  
- **CEP for IIoT:** 클라우드→엣지 컴퓨팅 전환  
- **PhiNets:** 이미지 처리 최적화, inverted residual block  
- **HANNAH:** 학습-배포 전체 자동화  

---

## 🧠 6. Use Cases in TinyML  

| 분야 | 내용 |
|------|------|
| 음성 인식 | TinySpeech, AttendNets (소형 음성·시각 주의모델) |
| 제스처 인식 | ASL(수어) 예측, EMG 기반 패턴 인식 |
| 환경 모니터링 | Capacitive sensing, Phenomics |
| 헬스케어 | 기침 감지, 노인 모니터링 (RetinaFace, MATE 등) |
| IoT 디바이스 | Always-on-voice wakeup, 저전력 VAD |
| 자율주행 | Piezo 센서 기반 차선 감지 |
| 이상 탐지 | TAC 및 센서 데이터 기반 Edge 검출 |

---

## 🚀 7. Prospects & Conclusion
- **Open Challenges:**  
  - 하드웨어 한계, 표준 벤치마크 부족, 인프라 제약  
- **Future Roadmap:**  
  - 모바일·태스크 오프로딩, 시스템 수준 통합  
- **결론:**  
  - TinyML은 초저전력 엣지 AI의 핵심 기술로, 지속적인 연구와 HW-ML 통합이 필요  

---
